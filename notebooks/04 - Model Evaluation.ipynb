{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the performance of classification models is a crucial component of the modeling process. The effective evaluation of a classification model entails producing accurate, robust measurements of model performance that are repeatable and useful. These measures should also reflect and explicitly measure the uncertainty inherent to the evaluation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll use the scikit-learn (sklearn) package to expore the use of several classification algorithms and corresponding measures of evaluation. Let's begin by fetching the Iris dataset from the UCI Machine Learning repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sepal Length  Sepal Width  Petal Length  Petal Width\n",
      "0           5.1          3.5           1.4          0.2\n",
      "1           4.9          3.0           1.4          0.2\n",
      "2           4.7          3.2           1.3          0.2\n",
      "3           4.6          3.1           1.5          0.2\n",
      "4           5.0          3.6           1.4          0.2\n",
      "\n",
      "0    Iris-setosa\n",
      "1    Iris-setosa\n",
      "2    Iris-setosa\n",
      "3    Iris-setosa\n",
      "4    Iris-setosa\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the file URL.\n",
    "file_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "data = pd.read_csv(file_url, names=['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width', 'Name'], header=None)\n",
    "\n",
    "X = data.iloc[:, :-1]  # features\n",
    "y = data.iloc[:, -1]  # class\n",
    "\n",
    "print(X.head())\n",
    "print()\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we should do is separate the available data into training and testing sets. We should always fit the model on the training data and then evaluate it on separate testing data. `sklearn` provides a convenient function to do this. Let's save 20% of our data for testing, and use the rest for fitting our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a simple classification model. Here, we use the _k_-nearest neighbor classifier, with the default parameters provided by the implementation in scikit-learn. We'll fit this model on the training data, which includes corresponding sets of training features (`X`) and class values (`y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate our classification model. Perhaps the simplest method of evaluation is the measure of accuracy. Accuracy is simply defined as the number of correct predictions over the total number of predictions.\n",
    "\n",
    "If we consider each prediction correct if it is identical to the corresponding instance's class value, then accuracy is simply the average number of correct predictions across our testing dataset. Using `NumPy`, we can implement a simple function to compute the average given two lists, one for the actual values and one for the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"Accuracy classification score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape = [n_instances]\n",
    "        Actual target values.\n",
    "    y_pred : array, shape = [n_instances]\n",
    "        Predicted target values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "        Returns the fraction of correctly classified instances.\n",
    "    \"\"\"\n",
    "    score = y_true == y_pred\n",
    "    return np.average(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use our fitted model to generate predictions for the testing data, and score the predictions according to their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_knn.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"{:.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `scikit-learn` also has a built-in accuracy scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = clf_knn.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"{:.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a confusion matrix to better understand how instances are being classified. A confusion matrix breaks down the model predictions on a dataset for which the actual labels are known. It produces a matrix that encodes all combinations of the actual and predicted labels.\n",
    "\n",
    "We can use `pandas` to implement a simple confusion matrix using the `crosstab` function that again uses the actual values and predicted values as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"Confusion matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape = [n_instances]\n",
    "        Actual target values.\n",
    "    y_pred : array, shape = [n_instances]\n",
    "        Predicted target values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cm : DataFrame\n",
    "        Returns the confusion matrix.\n",
    "    \"\"\"\n",
    "    return pd.crosstab(y_true, y_pred,\n",
    "                       rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iris-setosa</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-virginica</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted        Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "Actual                                                       \n",
       "Iris-setosa               10                0               0\n",
       "Iris-versicolor            0                9               1\n",
       "Iris-virginica             0                0              10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `scikit-learn` also has a built-in confusion matrix function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0,  9,  1],\n",
       "       [ 0,  0, 10]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, we find that a measure like accuracy may be misleading. In particular, for datasets with a skewed distribution of class values, a model with high accuracy may prove less useful than a model with lower accuracy. To see why, let's look at a different dataset.\n",
    "\n",
    "The Adults dataset is composed of information extracted from the U.S. Census Bureau database. The data includes a variety of personal information on over 32,000 individuals, with the task of predicting whether a given person makes over $50k per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0                  1       2           3   4                    5   \\\n",
      "0  39          State-gov   77516   Bachelors  13        Never-married   \n",
      "1  50   Self-emp-not-inc   83311   Bachelors  13   Married-civ-spouse   \n",
      "2  38            Private  215646     HS-grad   9             Divorced   \n",
      "3  53            Private  234721        11th   7   Married-civ-spouse   \n",
      "4  28            Private  338409   Bachelors  13   Married-civ-spouse   \n",
      "\n",
      "                   6               7       8        9     10  11  12  \\\n",
      "0        Adm-clerical   Not-in-family   White     Male  2174   0  40   \n",
      "1     Exec-managerial         Husband   White     Male     0   0  13   \n",
      "2   Handlers-cleaners   Not-in-family   White     Male     0   0  40   \n",
      "3   Handlers-cleaners         Husband   Black     Male     0   0  40   \n",
      "4      Prof-specialty            Wife   Black   Female     0   0  40   \n",
      "\n",
      "               13  \n",
      "0   United-States  \n",
      "1   United-States  \n",
      "2   United-States  \n",
      "3   United-States  \n",
      "4            Cuba  \n",
      "\n",
      "0     <=50K\n",
      "1     <=50K\n",
      "2     <=50K\n",
      "3     <=50K\n",
      "4     <=50K\n",
      "Name: 14, dtype: object\n"
     ]
    }
   ],
   "source": [
    "file_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "data2 = pd.read_csv(file_url, header=None)\n",
    "\n",
    "X = data2.iloc[:, :-1]  # features\n",
    "y = data2.iloc[:, -1]  # class\n",
    "\n",
    "print(X.head())\n",
    "print()\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that only about 24% of the individuals recorded in the dataset make over $50k per year. This is known as an imbalanced classification problem, where the class values are not equally represented in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " <=50K    24720\n",
       " >50K      7841\n",
       "Name: 14, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any modeling, we hve to preprocess the data. Here we transform categorical features into dummmy variables and convert the classes into binary `0` and `1` outcomes. Class `0` will correspond to `<=50K`, while Class `1` will correspond to `>50K`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's not even train a model. Instead, let's simply predict every testing instance as a Class `0` (<=50K) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762782128052\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "y_pred = np.zeros(y_test.shape)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that, because roughly 76% of the instances belong to Class `0`, we obtain 76% without a model. In some datasets, over 99% of the data could belong to a particular class, giving us over 99% accuracy! Often, however, we're interested in attempting to model the rarer outcome, even if it decreases the overall accuracy of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The receiver operating characteristic (ROC) curve is way to capture the tradeoff between true positive predictions and false positive predictions. To compute the curve for a binary classification problem, we need to calculate the probabilities for the rare (Class `1`) instances and the corresponding correct labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_knn2 = KNeighborsClassifier()\n",
    "clf_knn2.fit(X_train, y_train)\n",
    "y_prob = clf_knn2.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information, we can now generate the sequence of false positive rates and true positive rates that form the ROC curve. We can also calculate the area under the ROC curve (AUROC), a single measure of classification performance that is between 0.5 (random) and 1.0 (perfect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "                          \n",
    "# Calculate the fpr and tpr for all thresholds of the classification.\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve.\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUROC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a more robust estimate of classification performance, no matter what performance measure we apply, we can use cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Preprocess the training and testing sets separately.\n",
    "def preprocess(train, test):\n",
    "    train.iloc[:,:-1] = pd.get_dummies(train.iloc[:,:-1])\n",
    "    test.iloc[:,:-1] = pd.get_dummies(test.iloc[:,:-1])\n",
    "\n",
    "    le_train = LabelEncoder()\n",
    "    le_test = LabelEncoder()\n",
    "\n",
    "    train.iloc[:,-1] = le.fit_transform(train.iloc[:,-1])\n",
    "    test.iloc[:,-1] = le.fit_transform(test.iloc[:,-1])\n",
    "\n",
    "accs = []\n",
    "# Repeat the process five times.\n",
    "for i in range(5):\n",
    "    # Split the data into 10 stratified folds.\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    skf_acc = []\n",
    "\n",
    "    # Iterate over the folds.\n",
    "    for train_index, test_index in skf.split(data2.iloc[:,:-1], data2.iloc[:,-1]):\n",
    "        train, test = data2.iloc[train_index], data2.iloc[test_index]\n",
    "        print(train)\n",
    "        # Preprocess the training and testing sets.\n",
    "        X_train, y_train, X_test, y_test = preprocess(train, test)\n",
    "\n",
    "        # Fit the model on training set X and y.\n",
    "        clf_knn2.fit(X_train, y_train)\n",
    "\n",
    "        # Predict y for testing set X.\n",
    "        y_pred = clf_knn2.predict(X_test)\n",
    "\n",
    "        # Evaluate accuracy.\n",
    "        skf_acc.append(accuracy_score(y_test, y_pred))\n",
    "    accs.append(np.mean(skf_acc))\n",
    "\n",
    "print(pd.DataFrame(accs, columns=[name]).describe())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice applying what we've learned to a house price dataset for Ames, Iowa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_houses = pd.read_excel('http://www.amstat.org/publications/jse/v19n3/decock/AmesHousing.xls')\n",
    "print(df_houses.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Perform all of the steps necessary to prepare the data for classification.  For this dataset, these steps include dropping or filling missing values, separating the features and class, transforming categorical features to dummy variables, and binning SalePrice into two class outcomes, 'high' or 'low'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fit an artificial neural network (ANN) to the data, with 80% using for training and 20% used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print the accuracy of the fit ANN on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Show the ROC curve for the fit ANN on the testing data and print the area under the ROC curve (AUROC) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Again fit an artificial neural network (ANN) to the data, but this time using 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Print the average accuracy of the fit ANN across the 10 (testing) folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Print the average AUROC value of the fit ANN across the 10 (testing) folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
