{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the performance of classification models is a crucial component of the modeling process. The effective evaluation of a classification model entails producing accurate, robust measurements of model performance that are repeatable and useful. These measures should also reflect and explicitly measure the uncertainty inherent to the evaluation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll use the `scikit-learn` (`sklearn`) package to explore the use of several classification algorithms and corresponding measures of evaluation. Let's begin by fetching the Iris dataset from the UCI Machine Learning repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sepal Length  Sepal Width  Petal Length  Petal Width\n",
      "0           5.1          3.5           1.4          0.2\n",
      "1           4.9          3.0           1.4          0.2\n",
      "2           4.7          3.2           1.3          0.2\n",
      "3           4.6          3.1           1.5          0.2\n",
      "4           5.0          3.6           1.4          0.2\n",
      "\n",
      "0    Iris-setosa\n",
      "1    Iris-setosa\n",
      "2    Iris-setosa\n",
      "3    Iris-setosa\n",
      "4    Iris-setosa\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the file URL.\n",
    "file_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "data = pd.read_csv(file_url, names=['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width', 'Name'], header=None)\n",
    "\n",
    "X = data.iloc[:, :-1]  # features\n",
    "y = data.iloc[:, -1]  # class\n",
    "\n",
    "print(X.head())\n",
    "print()\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we should do is separate the available data into training and testing sets. We should always fit the model on the training data and then evaluate it on separate testing data. `sklearn` provides a convenient function to do this. Let's save 20% of our data for testing, and use the rest for fitting our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a simple classification model. Here, we use the _k_-nearest neighbor classifier, with the default parameters provided by the implementation in `sklearn`. We'll fit this model on the training data, which includes corresponding sets of training features (`X`) and class values (`y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's incorporate our preprocessing steps. To avoid \"snooping\" on our testing data, we should perform the preprocessing independently for the training and testing datasets.\n",
    "\n",
    "One point to note here is that as a consequence of this independence, the training and testing data may become incongruous. For example, if we are creating indicator variables for categorical data, a particular categorical value that appears in our testing data but not our training data will have an associated column in the testing data but not in the training data. As a consequence, the number of features we generate for the training and testing sets may differ; we thus have to address this potential difference. A simple way to address this issue is to ignore any columns in the testing data that do not appear in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Impute numeric features/columns.\n",
    "def impute_numeric(X):\n",
    "    # Initialize an Imputer with the appropriate imputation strategy.\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    for col in X.select_dtypes(include=['float64']).columns:\n",
    "        # Transform/impute the feature using the mean.\n",
    "        X[col] = X[col].fillna(X[col].mean())\n",
    "    return X\n",
    "\n",
    "# Impute nominal features/columns.\n",
    "def impute_nominal(X):\n",
    "    for col in X.select_dtypes(include=['object']).columns:\n",
    "        # Transform/impute the feature using the mode.\n",
    "        X[col] = X[col].fillna(pd.Series(X[col].value_counts().index[0]))\n",
    "    return X\n",
    "\n",
    "# Encode nominal features/columns with indicator/dummy variables.\n",
    "def dummify(X):\n",
    "    dummy_cols = [X.columns[i] for i, tp in enumerate(X.dtypes) if tp == 'object']\n",
    "    for col in dummy_cols:\n",
    "        temp = pd.get_dummies(X[col], prefix=col)\n",
    "        X = pd.concat([X, temp], axis=1).drop(col, axis=1)\n",
    "    return X\n",
    "\n",
    "# Encode and transform class values to numeric type.\n",
    "def encode(y): \n",
    "    le = LabelEncoder()\n",
    "    le.fit(y)\n",
    "    y = le.transform(y).astype(int)\n",
    "    y = pd.Series(y, name=data.columns[-1])\n",
    "    return y\n",
    "\n",
    "# Preprocess the training and testing sets separately.\n",
    "def preprocess(train, test):\n",
    "    # Prepare training data.\n",
    "    X_train = train.iloc[:,:-1]\n",
    "    y_train = train.iloc[:,-1]\n",
    "\n",
    "    X_train = impute_numeric(X_train)\n",
    "    X_train = impute_nominal(X_train)\n",
    "    X_train = dummify(X_train)\n",
    "    #y_train = encode(y_train)\n",
    "\n",
    "    # Prepare testing data.\n",
    "    X_test = test.iloc[:,:-1]\n",
    "    y_test = test.iloc[:,-1]\n",
    "\n",
    "    X_test = impute_numeric(X_test)\n",
    "    X_test = impute_nominal(X_test)\n",
    "    X_test = dummify(X_test)\n",
    "    #y_test = encode(y_test)\n",
    "\n",
    "    # Get the columns in training data but not in testing data.\n",
    "    col_to_add = np.setdiff1d(X_train.columns, X_test.columns)\n",
    "    # Add these columns to testing data, setting them equal to zero.\n",
    "    for c in col_to_add:\n",
    "        X_test[c] = 0\n",
    "    # Select and reorder the test columns using the train columns.\n",
    "    X_test = X_test[X_train.columns]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate our classification model. Perhaps the simplest method of evaluation is the measure of accuracy. Accuracy is simply defined as the number of correct predictions over the total number of predictions.\n",
    "\n",
    "If we consider each prediction correct if it is identical to the corresponding instance's class value, then accuracy is simply the average number of correct predictions across our testing dataset. Using `NumPy`, we can implement a simple function to compute the average given two lists, one for the actual values and one for the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"Accuracy classification score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape = [n_instances]\n",
    "        Actual target values.\n",
    "    y_pred : array, shape = [n_instances]\n",
    "        Predicted target values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "        Returns the fraction of correctly classified instances.\n",
    "    \"\"\"\n",
    "    score = y_true == y_pred\n",
    "    return np.average(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use our fitted model to generate predictions for the testing data, and score the predictions according to their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_knn.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"{:.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `sklearn` also has a built-in accuracy scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = clf_knn.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"{:.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a confusion matrix to better understand how instances are being classified. A confusion matrix breaks down the model predictions on a dataset for which the actual labels are known. It produces a matrix that encodes all combinations of the actual and predicted labels.\n",
    "\n",
    "We can use `pandas` to implement a simple confusion matrix using the `crosstab` function that again uses the actual values and predicted values as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"Confusion matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape = [n_instances]\n",
    "        Actual target values.\n",
    "    y_pred : array, shape = [n_instances]\n",
    "        Predicted target values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cm : DataFrame\n",
    "        Returns the confusion matrix.\n",
    "    \"\"\"\n",
    "    return pd.crosstab(y_true, y_pred,\n",
    "                       rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iris-setosa</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-virginica</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted        Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "Actual                                                       \n",
       "Iris-setosa               10                0               0\n",
       "Iris-versicolor            0               10               1\n",
       "Iris-virginica             0                0               9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `sklearn` also has a built-in confusion matrix function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0, 10,  1],\n",
       "       [ 0,  0,  9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, we find that a measure like accuracy may be misleading. In particular, for datasets with a skewed distribution of class values, a model with high accuracy may prove less useful than a model with lower accuracy. To see why, let's look at a different dataset.\n",
    "\n",
    "The Adults dataset is composed of information extracted from the U.S. Census Bureau database. The data includes a variety of personal information on over 32,000 individuals, with the task of predicting whether a given person makes over $50k per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0                  1       2           3   4                    5   \\\n",
      "0  39          State-gov   77516   Bachelors  13        Never-married   \n",
      "1  50   Self-emp-not-inc   83311   Bachelors  13   Married-civ-spouse   \n",
      "2  38            Private  215646     HS-grad   9             Divorced   \n",
      "3  53            Private  234721        11th   7   Married-civ-spouse   \n",
      "4  28            Private  338409   Bachelors  13   Married-civ-spouse   \n",
      "\n",
      "                   6               7       8        9     10  11  12  \\\n",
      "0        Adm-clerical   Not-in-family   White     Male  2174   0  40   \n",
      "1     Exec-managerial         Husband   White     Male     0   0  13   \n",
      "2   Handlers-cleaners   Not-in-family   White     Male     0   0  40   \n",
      "3   Handlers-cleaners         Husband   Black     Male     0   0  40   \n",
      "4      Prof-specialty            Wife   Black   Female     0   0  40   \n",
      "\n",
      "               13  \n",
      "0   United-States  \n",
      "1   United-States  \n",
      "2   United-States  \n",
      "3   United-States  \n",
      "4            Cuba  \n",
      "\n",
      "0     <=50K\n",
      "1     <=50K\n",
      "2     <=50K\n",
      "3     <=50K\n",
      "4     <=50K\n",
      "Name: 14, dtype: object\n"
     ]
    }
   ],
   "source": [
    "file_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "data2 = pd.read_csv(file_url, header=None)\n",
    "\n",
    "X = data2.iloc[:, :-1]  # features\n",
    "y = data2.iloc[:, -1]  # class\n",
    "\n",
    "print(X.head())\n",
    "print()\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that only about 24% of the individuals recorded in the dataset make over $50k per year. This is known as an imbalanced classification problem, where the class values are not equally represented in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " <=50K    24720\n",
       " >50K      7841\n",
       "Name: 14, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any modeling, we have to preprocess the data. Here we transform categorical features into dummy variables and convert the classes into binary `0` and `1` outcomes. Class `0` will correspond to `<=50K`, while Class `1` will correspond to `>50K`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's not even train a model. Instead, let's simply predict every testing instance as a Class `0` (<=50K) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755258713343\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "y_pred = np.zeros(y_test.shape)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that, because roughly 76% of the instances belong to Class `0`, we obtain 76% without a model. In some datasets, over 99% of the data could belong to a particular class, giving us over 99% accuracy! Often, however, we're interested in attempting to model the rarer outcome, even if it decreases the overall accuracy of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The receiver operating characteristic (ROC) curve is way to capture the tradeoff between true positive predictions and false positive predictions. To compute the curve for a binary classification problem, we need to calculate the probabilities for the rare (Class `1`) instances and the corresponding correct labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_knn2 = KNeighborsClassifier()\n",
    "clf_knn2.fit(X_train, y_train)\n",
    "y_prob = clf_knn2.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information, we can now generate the sequence of false positive rates and true positive rates that form the ROC curve. We can also calculate the area under the ROC curve (AUROC), a single measure of classification performance that is between 0.5 (random) and 1.0 (perfect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c7fbcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "                          \n",
    "# Calculate the fpr and tpr for all thresholds of the classification.\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve.\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUROC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a more robust estimate of classification performance, no matter what performance measure we apply, we can use cross-validation. In cross-validation, we'll use each instance as both a training and testing instance. We do this by separating the data into _k_ non-overlapping sets or folds, and training on _k-1_ folds will use the remaining fold as our testing set. We use each fold once as a testing set, resulting in _k_ iterations or repetitions of the learning process. In stratified cross-validation, we ensure that the proportion of class values assigned to each fold are approximately equal across folds.\n",
    "\n",
    "Here we use the `sklearn` function `StratifiedKFold` to perform a 10-fold stratified cross-validation procedure. Each fold, we preprocess the training and testing datasets, fit a model, generate predictions, and measure their accuracy. We can append these accuracy scores to a list, producing 10 accuracy scores, one for each repetition of the procedure. We can then average these accuracy scores to get the average accuracy of the algorithm across the 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             KNN\n",
      "count  10.000000\n",
      "mean    0.973333\n",
      "std     0.034427\n",
      "min     0.933333\n",
      "25%     0.933333\n",
      "50%     1.000000\n",
      "75%     1.000000\n",
      "max     1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Transform/encode the class values from nominal to numeric.\n",
    "data.iloc[:, -1] = encode(data.iloc[:, -1])\n",
    "\n",
    "# Split the data into 10 stratified folds.\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "skf_acc = []\n",
    "\n",
    "# Iterate over the folds.\n",
    "for train_index, test_index in skf.split(data.iloc[:,:-1], data.iloc[:,-1]):\n",
    "    train, test = data.iloc[train_index], data.iloc[test_index]\n",
    "\n",
    "    # Preprocess the training and testing sets.\n",
    "    X_train, y_train, X_test, y_test = preprocess(train, test)\n",
    "\n",
    "    # Fit the model on training set X and y.\n",
    "    clf_knn2.fit(X_train, y_train)\n",
    "\n",
    "    # Predict y for testing set X.\n",
    "    y_pred = clf_knn2.predict(X_test)\n",
    "\n",
    "    # Evaluate accuracy.\n",
    "    skf_acc.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(pd.DataFrame(skf_acc, columns=['KNN']).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice applying what we've learned to a house price dataset for Ames, Iowa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
      "0      1  526301100           20        RL         141.0     31770   Pave   \n",
      "1      2  526350040           20        RH          80.0     11622   Pave   \n",
      "2      3  526351010           20        RL          81.0     14267   Pave   \n",
      "3      4  526353030           20        RL          93.0     11160   Pave   \n",
      "4      5  527105010           60        RL          74.0     13830   Pave   \n",
      "\n",
      "  Alley Lot Shape Land Contour    ...     Pool Area Pool QC  Fence  \\\n",
      "0   NaN       IR1          Lvl    ...             0     NaN    NaN   \n",
      "1   NaN       Reg          Lvl    ...             0     NaN  MnPrv   \n",
      "2   NaN       IR1          Lvl    ...             0     NaN    NaN   \n",
      "3   NaN       Reg          Lvl    ...             0     NaN    NaN   \n",
      "4   NaN       IR1          Lvl    ...             0     NaN  MnPrv   \n",
      "\n",
      "  Misc Feature Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
      "0          NaN        0       5    2010       WD           Normal     215000  \n",
      "1          NaN        0       6    2010       WD           Normal     105000  \n",
      "2         Gar2    12500       6    2010       WD           Normal     172000  \n",
      "3          NaN        0       4    2010       WD           Normal     244000  \n",
      "4          NaN        0       3    2010       WD           Normal     189900  \n",
      "\n",
      "[5 rows x 82 columns]\n"
     ]
    }
   ],
   "source": [
    "df_houses = pd.read_excel('http://www.amstat.org/publications/jse/v19n3/decock/AmesHousing.xls')\n",
    "print(df_houses.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Perform all of the steps necessary to prepare the data for classification.  For this dataset, these steps include dropping or filling missing values, separating the features and class, transforming categorical features to dummy variables, and binning SalePrice into two class outcomes, 'high' or 'low'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fit an artificial neural network (ANN) to the data, with 80% using for training and 20% used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print the accuracy of the fit ANN on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Show the ROC curve for the fit ANN on the testing data and print the area under the ROC curve (AUROC) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Again fit an artificial neural network (ANN) to the data, but this time using 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Print the average accuracy of the fit ANN across the 10 (testing) folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Print the average AUROC value of the fit ANN across the 10 (testing) folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
